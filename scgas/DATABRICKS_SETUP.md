# ğŸš€ ConfiguraÃ§Ã£o do Databricks para o Projeto SCGAS

## ğŸ“‹ PrÃ©-requisitos

1. **Cluster Databricks ativo** no workspace
2. **Personal Access Token (PAT)** configurado
3. **Python 3.9+** instalado localmente

## ğŸ”§ Passos para ConfiguraÃ§Ã£o

### 1. **Encontrar o Cluster ID**

1. Acesse seu workspace Databricks: `https://adb-3588048019585666.6.azuredatabricks.net`
2. VÃ¡ para **Clusters** no menu lateral
3. Clique no cluster que deseja usar
4. Na aba **ConfiguraÃ§Ãµes**, copie o **Cluster ID**

### 2. **Criar Personal Access Token**

1. No Databricks, clique no seu usuÃ¡rio (canto superior direito)
2. Selecione **User Settings**
3. VÃ¡ para **Access Tokens**
4. Clique em **Generate New Token**
5. DÃª um nome (ex: "SCGAS Project")
6. Copie o token gerado

### 3. **Configurar o Arquivo Local**

Edite o arquivo `conf/local/databricks_cluster.yml`:

```yaml
databricks_cluster:
  cluster_id: "1234-567890-abcdef12"  # Substitua pelo seu Cluster ID
  personal_access_token: "dapi1234567890abcdef..."  # Substitua pelo seu PAT
  cluster_name: "Meu Cluster SCGAS"  # Nome para referÃªncia
```

### 4. **Instalar DependÃªncias**

```bash
pip3 install -r requirements.txt
```

### 5. **Testar ConexÃ£o**

```bash
# Testar se o Databricks Connect estÃ¡ funcionando
python3 -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
print(f'Spark version: {spark.version}')
print(f'App name: {spark.conf.get(\"spark.app.name\")}')
"
```

## ğŸ—ï¸ Estrutura do Projeto

```
scgas/
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ databricks.yml          # ConfiguraÃ§Ã£o base do Databricks
â”‚   â”‚   â””â”€â”€ catalog.yml             # CatÃ¡logo de datasets
â”‚   â””â”€â”€ local/
â”‚       â””â”€â”€ databricks_cluster.yml  # ConfiguraÃ§Ã£o local (nÃ£o commitada)
â”œâ”€â”€ src/scgas/
â”‚   â”œâ”€â”€ hooks.py                    # Hook para conectar ao Databricks
â”‚   â””â”€â”€ pipelines/
â”‚       â””â”€â”€ data_engineering/
â”‚           â”œâ”€â”€ nodes.py            # Nodes incluindo processamento Spark
â”‚           â””â”€â”€ pipeline.py         # Pipeline com 4 nodes
â””â”€â”€ requirements.txt                 # DependÃªncias incluindo databricks-connect
```

## ğŸš€ Executar o Pipeline

```bash
# Executar pipeline completo
kedro run --pipeline=data_engineering

# Executar apenas processamento Spark
kedro run --nodes=process_with_spark_node
```

## ğŸ“Š Nodes do Pipeline

1. **`authenticate_scgas_node`** - Autentica na API SCGAS
2. **`collect_measurements_node`** - Coleta dados da API
3. **`create_dataframe_node`** - Processa com pandas
4. **`process_with_spark_node`** - Processa com Spark do Databricks

## ğŸ” Monitoramento

- **Logs**: Verifique os logs do Kedro para status da conexÃ£o
- **Databricks**: Acesse o workspace para ver execuÃ§Ãµes do cluster
- **MÃ©tricas**: Use `kedro viz` para visualizar o pipeline

## âš ï¸ Troubleshooting

### **Erro de ConexÃ£o**
```bash
# Verificar se o cluster estÃ¡ ativo
# Verificar se o PAT Ã© vÃ¡lido
# Verificar se o Cluster ID estÃ¡ correto
```

### **Erro de VersÃ£o**
```bash
# Verificar compatibilidade do PySpark
pip3 list | grep pyspark
pip3 list | grep databricks
```

### **Fallback Local**
Se houver erro no Databricks, o sistema usa PySpark local automaticamente.

## ğŸ“š Recursos Adicionais

- [Databricks Connect Documentation](https://docs.databricks.com/dev-tools/databricks-connect.html)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [Kedro Documentation](https://docs.kedro.org/)
